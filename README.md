ğŸ“° News Aggregator

A full-stack news aggregation platform that collects articles from multiple Greek news sources, stores them in MongoDB, and presents them through a modern web interface with filtering, tagging, and administrative management.

The project is fully **dockerized**, reproducible on any machine, and designed as a **portfolio-ready application**.

---

## âœ¨ Features

- ğŸ•·ï¸ Web scraping from multiple news sources (e.g. Kathimerini, Naftemporiki)
- ğŸ—„ï¸ MongoDB storage with proper indexing
- ğŸš« Duplicate article prevention (unique URL index)
- ğŸ” Search and filtering by source, category, and tags
- ğŸ–¼ï¸ Article preview with images and metadata
- ğŸ” Admin panel for content management
- ğŸ³ Fully Dockerized (no local setup required)

---

## ğŸ§± Tech Stack

- **Backend**: Python (Flask)
- **Database**: MongoDB
- **Scraping**: Requests, BeautifulSoup
- **Frontend**: Jinja2, HTML, CSS
- **Containerization**: Docker, Docker Compose

---

## ğŸ“ Project Structure

```text
NewsAggregator/
â”‚
â”œâ”€â”€ app.py                 # Flask application entry point
â”œâ”€â”€ mongo.py               # MongoDB abstraction & indexes
â”œâ”€â”€ scraper_ka.py          # Kathimerini scraper
â”œâ”€â”€ scraper_na.py          # Naftemporiki scraper
â”œâ”€â”€ scraperall.py          # Run all scrapers
â”‚
â”œâ”€â”€ templates/             # Jinja2 HTML templates
â”œâ”€â”€ static/                # CSS, images, assets
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .env.example           # Environment variables template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
ğŸš€ Quick Start (Docker)
Prerequisites
Docker

Docker Compose

No Python, virtualenv, or MongoDB installation required.

1ï¸âƒ£ Clone the repository
git clone https://github.com/alexlenis/NewsAggregator.git
cd NewsAggregator
2ï¸âƒ£ Create environment variables
cp .env.example .env
The .env file is ignored by Git and used only locally or inside Docker.

3ï¸âƒ£ Build & run the application
docker compose up --build
4ï¸âƒ£ Open the application
ğŸŒ Web UI: http://localhost:5000

ğŸ—„ï¸ MongoDB runs inside Docker (internal network)

ğŸ” Admin Access (Demo)
For demonstration and evaluation purposes, the application includes a predefined administrator account.

Admin credentials:

Username: admin
Password: 1234
With admin access, a reviewer can:

Access the admin panel

Create, edit, and delete articles

Manually trigger scraping

Manage aggregated content

âš ï¸ Important Note
These credentials are intentionally simple and hardcoded only for demo / portfolio use.
In a production system, authentication would be implemented using secure password hashing and environment-based secrets.

ğŸ•·ï¸ Running the Scrapers
Scraping is executed inside the web container.

To run all scrapers:

docker compose exec web python scraperall.py
Scrapers support:

Page limits

Delay between requests

Source selection

ğŸ—„ï¸ Database Design
MongoDB database: news_db
Collection: articles

Indexes:

url (unique)

published_at

category

source

tags

This ensures:

Fast queries

Clean data

No duplicate articles

ğŸ”§ Environment Variables
Example (.env.example):

MONGO_URI=mongodb://mongo:27017/
MONGO_DB=news_db
FLASK_ENV=development
Sensitive configuration is never committed to the repository.

ğŸ§  Design Decisions
Docker-first architecture for reproducibility

MongoDB for flexible article schema

One scraper per source for maintainability

Unique URL index to prevent duplicates

Clear separation between scraping, storage, and presentation

ğŸ“Œ Why this project?
This project demonstrates:

Real-world backend development

Web scraping with error handling

Database modeling & indexing

Docker & container orchestration

Clean Git and environment practices

It is designed to be easy to run, review, and extend.

ğŸ”® Possible Improvements
Automated scheduling (cron / Celery)

REST API

User accounts & personalization

Full-text search

Cloud deployment

ğŸ‘¤ Author
Alex Lenis
GitHub: https://github.com/alexlenis

ğŸ“„ License
This project is intended for educational and portfolio purposes.
